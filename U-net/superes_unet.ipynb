{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"superes_unet.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"xZI3hLYfb6Hz","colab_type":"code","colab":{}},"source":["pip install --upgrade wandb"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"EStRYmr0Qz2E","colab_type":"code","colab":{}},"source":["!wget https://drive.google.com/open?id=1SsZpe5qHuwyrC8iulV1_KDecuyygxnni"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"EPS410KNTY85","colab_type":"code","colab":{}},"source":["# Run this cell to mount your Google Drive.\n","from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"0UFsY2sLcBgy","colab_type":"code","colab":{}},"source":["import wandb\n","from wandb.keras import WandbCallback\n","run=wandb.init(project=\"suppres\")\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"XVBceOFIcE0h","colab_type":"code","colab":{}},"source":["import random\n","import glob\n","import subprocess\n","import os\n","from PIL import Image\n","import numpy as np\n","import tensorflow as tf\n","from tensorflow.keras.models import Sequential\n","from tensorflow.keras import layers\n","from tensorflow.keras import backend as K\n","import tensorflow.keras as Ke\n","from tensorflow.keras.callbacks import Callback\n","# from tensorflow.keras.layers import BatchNormalization as BN\n","# from tensorflow.keras.layers import Input, Conv2D, BatchNormalization, Activation, Dense, Add, UpSampling2D, Concatenate, Layer, Dropout, MaxPool2D, Cropping2D,Lambda\n","from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau, Callback\n","from tensorflow.keras import *\n","from tensorflow.keras.layers import *\n","from tensorflow.keras.optimizers import Adam\n","from tensorflow.keras import *\n","import wandb\n","from wandb.keras import WandbCallback\n","import cv2\n","from tensorflow.keras.applications.vgg19 import VGG19\n","from tensorflow.keras.preprocessing import image\n","from tensorflow.keras.applications.vgg19 import preprocess_input\n","from tensorflow.keras.models import Model"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"8aLtY88sdzts","colab_type":"code","colab":{}},"source":["val_dir = 'data/test'\n","train_dir = 'data/train'\n","\n","# automatically get the data if it doesn't exist\n","if not os.path.exists(\"data\"):\n","    print(\"Downloading flower dataset...\")\n","    subprocess.check_output(\n","        \"mkdir data && curl https://storage.googleapis.com/wandb/flower-enhance.tar.gz | tar xz -C data\", shell=True)\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"JK9HlbBgd6VO","colab_type":"code","colab":{}},"source":["import numpy as np\n","import glob\n","import cv2\n","from PIL import Image\n","import os\n","\n","dest_path='data/train'\n","\n","def rotate(image, file_name,rotate_deg):\n","    rotate_90 = image.rotate(rotate_deg)\n","#     print(file_name.split('/'))\n","    rotate_90.save(os.path.join(dest_path,'R9'+file_name.split('/')[2]))\n","\n","def mirror(image,file_name):\n","    H_img = image.transpose(Image.FLIP_LEFT_RIGHT)\n","    V_img = image.transpose(Image.FLIP_TOP_BOTTOM)\n","\n","    V_img.save(os.path.join(dest_path,'VF'+file_name.split('/')[2]))\n","    H_img.save(os.path.join(dest_path,'HF'+file_name.split('/')[2]))\n","\n","def image_auggenerator( img_dir):\n","    \"\"\"A generator that returns small images and large images.  DO NOT ALTER the validation set\"\"\"\n","    input_filenames = glob.glob(img_dir + \"/*-in.jpg\")\n","    counter = 0\n","    for i in range (0,len(input_filenames)):\n","        img=input_filenames[counter]\n","        in_image=Image.open(img)#cv2.imread(img)\n","        rotate(in_image,img,90)\n","        mirror(in_image,img)\n","        out_image=Image.open(img.replace(\"-in.jpg\", \"-out.jpg\"))#cv2.imread(img.replace(\"-in.jpg\", \"-out.jpg\"))\n","        rotate(out_image,img.replace(\"-in.jpg\", \"-out.jpg\"),90)\n","        mirror(out_image,img.replace(\"-in.jpg\", \"-out.jpg\"))\n","        counter+=1\n","\n","img_dir='data/train'\n","\n","image_auggenerator(img_dir)\n","print(len(os.listdir('data/train')))"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"STYneJTxd_fN","colab_type":"code","colab":{}},"source":["config = run.config\n","config.num_epochs = 10\n","config.batch_size = 4\n","config.input_height = 64\n","config.input_width = 64\n","config.output_height = 256\n","config.output_width = 256\n","\n","\n","config.steps_per_epoch = len(\n","    glob.glob(train_dir + \"/*-in.jpg\")) // config.batch_size\n","config.val_steps_per_epoch = len(\n","    glob.glob(val_dir + \"/*-in.jpg\")) // config.batch_size\n","\n","\n","\n","\n","def image_generator(batch_size, img_dir):\n","    \"\"\"A generator that returns small images and large images.  DO NOT ALTER the validation set\"\"\"\n","    input_filenames = glob.glob(img_dir + \"/*-in.jpg\")\n","    counter = 0\n","    while True:\n","        small_images = np.zeros(\n","            (batch_size, config.input_width, config.input_height, 3))\n","        large_images = np.zeros(\n","            (batch_size, config.output_width, config.output_height, 3))\n","        random.shuffle(input_filenames)\n","        if counter+batch_size >= len(input_filenames):\n","            counter = 0\n","        for i in range(batch_size):\n","            img = input_filenames[counter + i]\n","            in_img=cv2.imread((img))\n","            in_img=cv2.resize(in_img,(64,64))\n","            small_images[i] = np.array(in_img) / 255.0\n","            large_images[i] = np.array(\n","                cv2.imread(img.replace(\"-in.jpg\", \"-out.jpg\"))) / 255.0\n","        yield (small_images, large_images)\n","        counter += batch_size\n","\n","\n","def perceptual_distance(y_true, y_pred):\n","    \"\"\"Calculate perceptual distance, DO NOT ALTER\"\"\"\n","    y_true *= 255\n","    y_pred *= 255\n","    rmean = (y_true[:, :, :, 0] + y_pred[:, :, :, 0]) / 2\n","    r = y_true[:, :, :, 0] - y_pred[:, :, :, 0]\n","    g = y_true[:, :, :, 1] - y_pred[:, :, :, 1]\n","    b = y_true[:, :, :, 2] - y_pred[:, :, :, 2]\n","\n","    return K.mean(K.sqrt((((512+rmean)*r*r)/256) + 4*g*g + (((767-rmean)*b*b)/256)))\n","\n","\n","val_generator = image_generator(config.batch_size, val_dir)\n","in_sample_images, out_sample_images = next(val_generator)\n","\n","\n","class ImageLogger(Callback):\n","    def on_epoch_end(self, epoch, logs):\n","        preds = self.model.predict(in_sample_images)\n","        in_resized = []\n","        for arr in in_sample_images:\n","            # Simple upsampling\n","            in_resized.append(arr.repeat(8, axis=0).repeat(8, axis=1))\n","        wandb.log({\n","            \"examples\": [wandb.Image(np.concatenate([in_resized[i] * 255, o * 255, out_sample_images[i] * 255], axis=1)) for i, o in enumerate(preds)]\n","        }, commit=False)\n","\n","        \n","\n","        \n","        \n","def ms_ssmi_loss(y_true,y_pred):\n","  ssim_loss=K.mean(tf.image.ssim_multiscale(y_true,y_pred,1.0))\n","  l1_loss=K.sum(tf.keras.losses.mean_absolute_error(y_true, y_pred),axis=1)\n","  loss = 1.5*ssim_loss+l1_loss*(0.5)\n","  return loss\n","  \n","\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"mYbV2Ii4b6_T","colab_type":"code","colab":{}},"source":["def unet(pretrained_weights = None,input_size = (32,32,3)):\n","    inputs = Input(input_size)\n","    conv1 = Conv2D(64, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(inputs)\n","    conv1 = Conv2D(64, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv1)\n","    pool1 = MaxPool2D(pool_size=(2, 2))(conv1)\n","    conv2 = Conv2D(128, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(pool1)\n","    conv2 = Conv2D(128, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv2)\n","    pool2 = MaxPool2D(pool_size=(2, 2))(conv2)\n","    conv3 = Conv2D(256, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(pool2)\n","    conv3 = Conv2D(256, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv3)\n","    pool3 = MaxPool2D(pool_size=(2, 2))(conv3)\n","    conv4 = Conv2D(512, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(pool3)\n","    conv4 = Conv2D(512, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv4)\n","    drop4 = Dropout(0.5)(conv4)\n","    pool4 = MaxPool2D(pool_size=(2, 2))(drop4)\n","\n","    conv5 = Conv2D(1024, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(pool4)\n","    conv5 = Conv2D(1024, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv5)\n","    drop5 = Dropout(0.5)(conv5)\n","\n","    up6 = Conv2D(512, 2, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(UpSampling2D(size = (2,2))(drop5))\n","    merge6 = Concatenate([drop4,up6], axis = 3)\n","    conv6 = Conv2D(512, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(merge6)\n","    conv6 = Conv2D(512, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv6)\n","\n","    up7 = Conv2D(256, 2, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(UpSampling2D(size = (2,2))(conv6))\n","    merge7 = Concatenate([conv3,up7], axis = 3)\n","    conv7 = Conv2D(256, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(merge7)\n","    conv7 = Conv2D(256, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv7)\n","\n","    up8 = Conv2D(128, 2, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(UpSampling2D(size = (2,2))(conv7))\n","    merge8 = Concatenate([conv2,up8], axis = 3)\n","    conv8 = Conv2D(128, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(merge8)\n","    conv8 = Conv2D(128, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv8)\n","\n","    up9 = Conv2D(64, 2, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(UpSampling2D(size = (2,2))(conv8))\n","    merge9 = Concatenate([conv1,up9], axis = 3)\n","    conv9 = Conv2D(64, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(merge9)\n","    conv9 = Conv2D(64, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv9)\n","    conv9 = Conv2D(2, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv9)\n","    conv10 = Conv2D(1, 1, activation = 'sigmoid')(conv9)\n","\n","    model = Model(input = inputs, output = conv10)\n","\n","    #model.compile(optimizer = Adam(lr = 1e-4), loss = 'binary_crossentropy', metrics = ['accuracy'])\n","    \n","    print(model.summary())\n","    return model"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"rpFwWZm8e1oq","colab_type":"code","colab":{}},"source":["model =unet()\n","\n","model.compile(optimizer=Adam(lr=0.005), loss='mae', metrics=[perceptual_distance])\n","\n","model.fit_generator(image_generator(config.batch_size, train_dir),\n","                    steps_per_epoch=config.steps_per_epoch,\n","                    epochs=config.num_epochs, callbacks=[\n","                        ImageLogger(), WandbCallback()],\n","                    validation_steps=config.val_steps_per_epoch,\n","                    validation_data=val_generator)"],"execution_count":0,"outputs":[]}]}